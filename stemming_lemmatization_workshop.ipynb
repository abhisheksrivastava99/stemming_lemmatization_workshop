{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "997012a9-221b-4a74-b3ee-b6be1a954c84",
   "metadata": {},
   "source": [
    "# Interactive Stemming and Lemmatization Workshop\n",
    "\n",
    "Welcome to this interactive workshop on stemming and lemmatization in Natural Language Processing! This notebook will guide you through various techniques for reducing words to their base forms, from basic implementations to advanced methods using popular NLP libraries.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Basic Implementation](#basic)\n",
    "3. [Interactive Concept Explanation](#concept)\n",
    "4. [Advanced Implementation](#advanced)\n",
    "5. [Interactive Visualizations](#visualization)\n",
    "6. [Challenges and Edge Cases](#challenges)\n",
    "7. [Conclusion and Further Resources](#conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01aa16d4-7d4f-4f66-89b4-619b8ab8243b",
   "metadata": {},
   "source": [
    "<a id='introduction'></a>\n",
    "## 1. Introduction to Stemming and Lemmatization\n",
    "\n",
    "### What are Stemming and Lemmatization?\n",
    "\n",
    "**Stemming** is the process of reducing a word to its stem or root form by removing suffixes and prefixes. It's a rule-based approach that may not always result in a valid word.\n",
    "\n",
    "**Lemmatization** is the process of reducing a word to its base form (lemma) using vocabulary and morphological analysis. It always results in a valid word.\n",
    "\n",
    "### Key Differences\n",
    "\n",
    "1. **Accuracy**\n",
    "   - Stemming: Less accurate, may produce non-words\n",
    "   - Lemmatization: More accurate, produces valid words\n",
    "\n",
    "2. **Speed**\n",
    "   - Stemming: Faster, rule-based\n",
    "   - Lemmatization: Slower, dictionary-based\n",
    "\n",
    "3. **Use Cases**\n",
    "   - Stemming: Information retrieval, search engines\n",
    "   - Lemmatization: Text analysis, machine learning\n",
    "\n",
    "### Real-World Applications\n",
    "\n",
    "- **Search Engines**: Finding relevant documents\n",
    "- **Sentiment Analysis**: Reducing words to base forms\n",
    "- **Chatbots**: Understanding user queries\n",
    "- **Text Classification**: Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90315453-c27a-4d48-8335-f0ff3779b8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/samarmohanty/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/samarmohanty/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/samarmohanty/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import re\n",
    "import networkx as nx\n",
    "import graphviz\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Initialize stemmers and lemmatizer\n",
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "snowball = SnowballStemmer('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('dark_background')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6985dce9-e9a5-43ad-b0fb-384e58b1938d",
   "metadata": {},
   "source": [
    "<a id='basic'></a>\n",
    "## 2. Basic Implementation from Scratch\n",
    "\n",
    "Let's implement basic stemming and lemmatization from scratch to understand the fundamental concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d621d87-aeac-446e-9063-dca6f13ad249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "372a452ca8ec401180f8a5c81dd7cba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Textarea(value='Enter a word to stem and lemmatize...', description='Word:', layout=Layo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.update_word_forms(word)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stem_word_custom(word):\n",
    "    \"\"\"Custom stemming implementation\"\"\"\n",
    "    # Convert to lowercase\n",
    "    word = word.lower()\n",
    "    \n",
    "    # Common suffixes to remove\n",
    "    suffixes = ['ing', 'ed', 'er', 'est', 'ly', 's', 'es']\n",
    "    \n",
    "    # Remove suffixes\n",
    "    for suffix in suffixes:\n",
    "        if word.endswith(suffix):\n",
    "            word = word[:-len(suffix)]\n",
    "    \n",
    "    return word\n",
    "\n",
    "def lemmatize_word_custom(word):\n",
    "    \"\"\"Custom lemmatization implementation\"\"\"\n",
    "    # Convert to lowercase\n",
    "    word = word.lower()\n",
    "    \n",
    "    # Basic dictionary of word forms\n",
    "    word_forms = {\n",
    "        'running': 'run',\n",
    "        'ran': 'run',\n",
    "        'runs': 'run',\n",
    "        'better': 'good',\n",
    "        'best': 'good',\n",
    "        'went': 'go',\n",
    "        'going': 'go',\n",
    "        'goes': 'go'\n",
    "    }\n",
    "    \n",
    "    return word_forms.get(word, word)\n",
    "\n",
    "# Interactive widget for custom text input\n",
    "text_input = widgets.Textarea(\n",
    "    value='Enter a word to stem and lemmatize...',\n",
    "    placeholder='Type a word',\n",
    "    description='Word:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '80%', 'height': '100px'}\n",
    ")\n",
    "\n",
    "def update_word_forms(word):\n",
    "    print(f\"Original word: {word}\")\n",
    "    print(f\"Stemmed (custom): {stem_word_custom(word)}\")\n",
    "    print(f\"Lemmatized (custom): {lemmatize_word_custom(word)}\")\n",
    "    print(f\"\\nStemmed (Porter): {porter.stem(word)}\")\n",
    "    print(f\"Lemmatized (NLTK): {lemmatizer.lemmatize(word)}\")\n",
    "\n",
    "interact(update_word_forms, word=text_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa270b99-19a1-4eed-8819-293d06a03896",
   "metadata": {},
   "source": [
    "<a id='concept'></a>\n",
    "## 3. Interactive Concept Explanation\n",
    "\n",
    "Let's explore how different stemming and lemmatization techniques transform words. We'll create an interactive tool that shows the transformation process step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57823e51-a07c-4d06-b20a-58d408dba48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36ea3852d854270bcc213b5eb1f7313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='running', description='Word:', layout=Layout(width='80%'), style=TextStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.update_transformations(word, method)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_word_transformations(word):\n",
    "    \"\"\"Get all transformations of a word using different methods\"\"\"\n",
    "    transformations = {\n",
    "        'Original': word,\n",
    "        'Porter Stemmer': porter.stem(word),\n",
    "        'Lancaster Stemmer': lancaster.stem(word),\n",
    "        'Snowball Stemmer': snowball.stem(word),\n",
    "        'NLTK Lemmatizer': lemmatizer.lemmatize(word),\n",
    "        'spaCy Lemmatizer': nlp(word)[0].lemma_\n",
    "    }\n",
    "    return transformations\n",
    "\n",
    "def visualize_transformations(word):\n",
    "    \"\"\"Create interactive visualization of word transformations\"\"\"\n",
    "    # Get transformations\n",
    "    transformations = get_word_transformations(word)\n",
    "    \n",
    "    # Create a bar plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    methods = list(transformations.keys())\n",
    "    results = list(transformations.values())\n",
    "    \n",
    "    # Create bar plot\n",
    "    bars = plt.bar(methods, results)\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title(f'Word Transformations for: \"{word}\"')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylabel('Result')\n",
    "    \n",
    "    # Add value labels on top of bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height}',\n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed transformations\n",
    "    print(\"\\nDetailed Transformations:\")\n",
    "    for method, result in transformations.items():\n",
    "        print(f\"{method}: {result}\")\n",
    "\n",
    "# Interactive widgets\n",
    "word_input = widgets.Text(\n",
    "    value='running',\n",
    "    description='Word:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '80%'}\n",
    ")\n",
    "\n",
    "method_dropdown = widgets.Dropdown(\n",
    "    options=['All', 'Porter Stemmer', 'Lancaster Stemmer', 'Snowball Stemmer', \n",
    "             'NLTK Lemmatizer', 'spaCy Lemmatizer'],\n",
    "    value='All',\n",
    "    description='Method:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '80%'}\n",
    ")\n",
    "\n",
    "def update_transformations(word, method):\n",
    "    \"\"\"Update the visualization based on user input\"\"\"\n",
    "    if method == 'All':\n",
    "        visualize_transformations(word)\n",
    "    else:\n",
    "        transformations = get_word_transformations(word)\n",
    "        print(f\"\\nOriginal word: {word}\")\n",
    "        print(f\"{method} result: {transformations[method]}\")\n",
    "\n",
    "# Create interactive widget\n",
    "interact(update_transformations, word=word_input, method=method_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcfcc0a-f740-4768-9242-1b6ddcc5d6a9",
   "metadata": {},
   "source": [
    "### Common Patterns in Word Transformations\n",
    "\n",
    "1. **Stemming Patterns**\n",
    "   - Removing 'ing' (running → run)\n",
    "   - Removing 'ed' (played → play)\n",
    "   - Removing 's' (cats → cat)\n",
    "   - Removing 'er' (faster → fast)\n",
    "   - Removing 'est' (fastest → fast)\n",
    "\n",
    "2. **Lemmatization Patterns**\n",
    "   - Converting to base form (better → good)\n",
    "   - Handling irregular verbs (went → go)\n",
    "   - Preserving word meaning (running → run)\n",
    "   - Handling adjectives (better → good)\n",
    "   - Handling adverbs (quickly → quick)\n",
    "\n",
    "### Interactive Pattern Testing\n",
    "\n",
    "Try these example words to see different patterns:\n",
    "- running, ran, runs\n",
    "- better, best, good\n",
    "- quickly, quick, quicker\n",
    "- playing, played, plays\n",
    "- faster, fast, fastest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00bf6c83-7a70-406a-85c9-a97e53349021",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcf01aa04b3d46abb34462de4e188c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='running', description='Test Word:', layout=Layout(width='80%'), style=TextSt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.test_patterns(word)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_patterns(word):\n",
    "    \"\"\"Test different patterns on a word\"\"\"\n",
    "    # Get word forms\n",
    "    forms = {\n",
    "        'Original': word,\n",
    "        'Porter Stem': porter.stem(word),\n",
    "        'NLTK Lemma': lemmatizer.lemmatize(word),\n",
    "        'spaCy Lemma': nlp(word)[0].lemma_\n",
    "    }\n",
    "    \n",
    "    # Create a table\n",
    "    table = pd.DataFrame([forms])\n",
    "    table = table.T\n",
    "    table.columns = ['Result']\n",
    "    \n",
    "    # Display the table\n",
    "    display(table)\n",
    "    \n",
    "    # Print pattern explanation\n",
    "    print(\"\\nPattern Explanation:\")\n",
    "    if word.endswith('ing'):\n",
    "        print(\"- Removed 'ing' suffix\")\n",
    "    if word.endswith('ed'):\n",
    "        print(\"- Removed 'ed' suffix\")\n",
    "    if word.endswith('s'):\n",
    "        print(\"- Removed 's' suffix\")\n",
    "    if word.endswith('er'):\n",
    "        print(\"- Removed 'er' suffix\")\n",
    "    if word.endswith('est'):\n",
    "        print(\"- Removed 'est' suffix\")\n",
    "\n",
    "# Interactive widget for pattern testing\n",
    "pattern_input = widgets.Text(\n",
    "    value='running',\n",
    "    description='Test Word:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '80%'}\n",
    ")\n",
    "\n",
    "interact(test_patterns, word=pattern_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13888e3d-1118-4557-85d4-522942a058d6",
   "metadata": {},
   "source": [
    "### Understanding Stemming Patterns\n",
    "\n",
    "Let's explore different stemming algorithms and their specific patterns. We'll create an interactive tool that shows how each stemmer processes words differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca2b3a7c-7249-4ef5-a8d4-099bec0c655c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9257c25b573e4b019dd82255ece5c567",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='running', description='Word:', layout=Layout(width='80%'), style=TextStyle(d…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.update_stemming_analysis(word, stemmer_type)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze_stemming_patterns(word):\n",
    "    \"\"\"Analyze and visualize stemming patterns for different algorithms\"\"\"\n",
    "    # Get stems from different algorithms\n",
    "    stems = {\n",
    "        'Porter Stemmer': porter.stem(word),\n",
    "        'Lancaster Stemmer': lancaster.stem(word),\n",
    "        'Snowball Stemmer': snowball.stem(word)\n",
    "    }\n",
    "    \n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    algorithms = list(stems.keys())\n",
    "    results = list(stems.values())\n",
    "    \n",
    "    # Create bar plot\n",
    "    bars = plt.bar(algorithms, results)\n",
    "    \n",
    "    # Customize the plot\n",
    "    plt.title(f'Stemming Patterns for: \"{word}\"')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylabel('Stemmed Result')\n",
    "    \n",
    "    # Add value labels on top of bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height}',\n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print detailed analysis\n",
    "    print(\"\\nDetailed Stemming Analysis:\")\n",
    "    for algorithm, stem in stems.items():\n",
    "        print(f\"\\n{algorithm}:\")\n",
    "        print(f\"Original: {word}\")\n",
    "        print(f\"Stemmed: {stem}\")\n",
    "        \n",
    "        # Analyze patterns\n",
    "        if word != stem:\n",
    "            if word.endswith('ing') and stem == word[:-3]:\n",
    "                print(\"Pattern: Removed 'ing' suffix\")\n",
    "            elif word.endswith('ed') and stem == word[:-2]:\n",
    "                print(\"Pattern: Removed 'ed' suffix\")\n",
    "            elif word.endswith('er') and stem == word[:-2]:\n",
    "                print(\"Pattern: Removed 'er' suffix\")\n",
    "            elif word.endswith('est') and stem == word[:-3]:\n",
    "                print(\"Pattern: Removed 'est' suffix\")\n",
    "            elif word.endswith('s') and stem == word[:-1]:\n",
    "                print(\"Pattern: Removed 's' suffix\")\n",
    "            elif word.endswith('es') and stem == word[:-2]:\n",
    "                print(\"Pattern: Removed 'es' suffix\")\n",
    "            elif word.endswith('ly') and stem == word[:-2]:\n",
    "                print(\"Pattern: Removed 'ly' suffix\")\n",
    "            else:\n",
    "                print(\"Pattern: Complex transformation\")\n",
    "\n",
    "# Interactive widgets\n",
    "stem_word_input = widgets.Text(\n",
    "    value='running',\n",
    "    description='Word:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '80%'}\n",
    ")\n",
    "\n",
    "stem_type_dropdown = widgets.Dropdown(\n",
    "    options=['All', 'Porter', 'Lancaster', 'Snowball'],\n",
    "    value='All',\n",
    "    description='Stemmer:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '80%'}\n",
    ")\n",
    "\n",
    "def update_stemming_analysis(word, stemmer_type):\n",
    "    \"\"\"Update the stemming analysis based on user input\"\"\"\n",
    "    if stemmer_type == 'All':\n",
    "        analyze_stemming_patterns(word)\n",
    "    else:\n",
    "        if stemmer_type == 'Porter':\n",
    "            stem = porter.stem(word)\n",
    "            stemmer_name = 'Porter Stemmer'\n",
    "        elif stemmer_type == 'Lancaster':\n",
    "            stem = lancaster.stem(word)\n",
    "            stemmer_name = 'Lancaster Stemmer'\n",
    "        else:\n",
    "            stem = snowball.stem(word)\n",
    "            stemmer_name = 'Snowball Stemmer'\n",
    "            \n",
    "        print(f\"\\n{stemmer_name} Analysis:\")\n",
    "        print(f\"Original: {word}\")\n",
    "        print(f\"Stemmed: {stem}\")\n",
    "        \n",
    "        # Analyze pattern\n",
    "        if word != stem:\n",
    "            if word.endswith('ing') and stem == word[:-3]:\n",
    "                print(\"Pattern: Removed 'ing' suffix\")\n",
    "            elif word.endswith('ed') and stem == word[:-2]:\n",
    "                print(\"Pattern: Removed 'ed' suffix\")\n",
    "            elif word.endswith('er') and stem == word[:-2]:\n",
    "                print(\"Pattern: Removed 'er' suffix\")\n",
    "            elif word.endswith('est') and stem == word[:-3]:\n",
    "                print(\"Pattern: Removed 'est' suffix\")\n",
    "            elif word.endswith('s') and stem == word[:-1]:\n",
    "                print(\"Pattern: Removed 's' suffix\")\n",
    "            elif word.endswith('es') and stem == word[:-2]:\n",
    "                print(\"Pattern: Removed 'es' suffix\")\n",
    "            elif word.endswith('ly') and stem == word[:-2]:\n",
    "                print(\"Pattern: Removed 'ly' suffix\")\n",
    "            else:\n",
    "                print(\"Pattern: Complex transformation\")\n",
    "\n",
    "# Create interactive widget\n",
    "interact(update_stemming_analysis, word=stem_word_input, stemmer_type=stem_type_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83e936e-45af-4f91-9191-9dfa30dc0201",
   "metadata": {},
   "source": [
    "### Common Stemming Patterns\n",
    "\n",
    "1. **Porter Stemmer**\n",
    "   - Most commonly used stemmer\n",
    "   - Conservative approach\n",
    "   - Examples:\n",
    "     - running → run\n",
    "     - playing → play\n",
    "     - faster → fast\n",
    "\n",
    "2. **Lancaster Stemmer**\n",
    "   - More aggressive than Porter\n",
    "   - May produce shorter stems\n",
    "   - Examples:\n",
    "     - running → run\n",
    "     - playing → play\n",
    "     - faster → fast\n",
    "\n",
    "3. **Snowball Stemmer**\n",
    "   - Also known as Porter2\n",
    "   - Slightly improved version of Porter\n",
    "   - Examples:\n",
    "     - running → run\n",
    "     - playing → play\n",
    "     - faster → fast\n",
    "\n",
    "### Interactive Pattern Testing\n",
    "\n",
    "Try these example words to see different patterns:\n",
    "- running, ran, runs\n",
    "- playing, played, plays\n",
    "- faster, fast, fastest\n",
    "- quickly, quick, quicker\n",
    "- better, best, good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a5642dd-afbf-46d9-aa74-676123deffcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c92d62e50f784e63a4573e3cb3bf25f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='running', description='Compare Word:', layout=Layout(width='80%'), style=Tex…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.compare_stemming_patterns(word)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_stemming_patterns(word):\n",
    "    \"\"\"Compare stemming patterns across different algorithms\"\"\"\n",
    "    # Get stems from different algorithms\n",
    "    stems = {\n",
    "        'Porter': porter.stem(word),\n",
    "        'Lancaster': lancaster.stem(word),\n",
    "        'Snowball': snowball.stem(word)\n",
    "    }\n",
    "    \n",
    "    # Create comparison table\n",
    "    comparison = pd.DataFrame([stems])\n",
    "    comparison = comparison.T\n",
    "    comparison.columns = ['Stemmed Result']\n",
    "    \n",
    "    # Display the table\n",
    "    display(comparison)\n",
    "    \n",
    "    # Analyze differences\n",
    "    print(\"\\nPattern Analysis:\")\n",
    "    if len(set(stems.values())) == 1:\n",
    "        print(\"All stemmers produced the same result\")\n",
    "    else:\n",
    "        print(\"Different stemmers produced different results:\")\n",
    "        for stemmer, stem in stems.items():\n",
    "            print(f\"- {stemmer}: {stem}\")\n",
    "    \n",
    "    # Show pattern explanation\n",
    "    print(\"\\nPattern Explanation:\")\n",
    "    if word.endswith('ing'):\n",
    "        print(\"- Removed 'ing' suffix\")\n",
    "    if word.endswith('ed'):\n",
    "        print(\"- Removed 'ed' suffix\")\n",
    "    if word.endswith('s'):\n",
    "        print(\"- Removed 's' suffix\")\n",
    "    if word.endswith('er'):\n",
    "        print(\"- Removed 'er' suffix\")\n",
    "    if word.endswith('est'):\n",
    "        print(\"- Removed 'est' suffix\")\n",
    "    if word.endswith('ly'):\n",
    "        print(\"- Removed 'ly' suffix\")\n",
    "\n",
    "# Interactive widget for pattern comparison\n",
    "compare_input = widgets.Text(\n",
    "    value='running',\n",
    "    description='Compare Word:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '80%'}\n",
    ")\n",
    "\n",
    "interact(compare_stemming_patterns, word=compare_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f30ded-583e-4678-b328-eec8cf0336a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
