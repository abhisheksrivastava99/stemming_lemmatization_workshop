{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b944b47-4a3a-407d-a42c-28cacc33fec2",
   "metadata": {},
   "source": [
    "<a id='advanced'></a>\n",
    "## 4. Advanced Implementation with Libraries\n",
    "\n",
    "Let's explore advanced implementations using popular NLP libraries. We'll compare different stemming and lemmatization techniques and analyze their performance on various types of text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4157e70-ba1b-4d47-a425-81416f3177dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/samarmohanty/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/samarmohanty/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/samarmohanty/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import spacy\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer, SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "import re\n",
    "import networkx as nx\n",
    "import graphviz\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Initialize stemmers and lemmatizer\n",
    "porter = PorterStemmer()\n",
    "lancaster = LancasterStemmer()\n",
    "snowball = SnowballStemmer('english')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Set style for better visualizations\n",
    "plt.style.use('dark_background')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfc70397-1fe3-499b-8937-4f953e1be610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805ac8ebfe3f45a3bc34896777bcd01f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Textarea(value='The quick brown foxes are running faster than the lazy dogs. They are pl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.update_advanced_processing(text, method)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def advanced_text_processing(text):\n",
    "    \"\"\"Advanced text processing with multiple stemming and lemmatization methods\"\"\"\n",
    "    # Split text into words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Process each word with different methods\n",
    "    results = {\n",
    "        'Original': words,\n",
    "        'Porter Stemmer': [porter.stem(word) for word in words],\n",
    "        'Lancaster Stemmer': [lancaster.stem(word) for word in words],\n",
    "        'Snowball Stemmer': [snowball.stem(word) for word in words],\n",
    "        'NLTK Lemmatizer': [lemmatizer.lemmatize(word) for word in words],\n",
    "        'spaCy Lemmatizer': [nlp(word)[0].lemma_ for word in words]\n",
    "    }\n",
    "    \n",
    "    # Create DataFrame for comparison\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Display results\n",
    "    print(\"Text Processing Results:\")\n",
    "    display(df)\n",
    "    \n",
    "    # Calculate statistics\n",
    "    print(\"\\nStatistics:\")\n",
    "    for method, processed_words in results.items():\n",
    "        if method != 'Original':\n",
    "            unique_words = len(set(processed_words))\n",
    "            reduction = (len(words) - unique_words) / len(words) * 100\n",
    "            print(f\"\\n{method}:\")\n",
    "            print(f\"- Unique words: {unique_words}\")\n",
    "            print(f\"- Reduction: {reduction:.2f}%\")\n",
    "    \n",
    "    # Visualize word frequency\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # Plot original vs processed word frequencies\n",
    "    plt.subplot(1, 2, 1)\n",
    "    original_freq = pd.Series(words).value_counts().head(10)\n",
    "    original_freq.plot(kind='bar')\n",
    "    plt.title('Top 10 Original Words')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    # Plot processed word frequencies\n",
    "    plt.subplot(1, 2, 2)\n",
    "    processed_freq = pd.Series(results['NLTK Lemmatizer']).value_counts().head(10)\n",
    "    processed_freq.plot(kind='bar')\n",
    "    plt.title('Top 10 Processed Words')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Interactive widgets\n",
    "text_input = widgets.Textarea(\n",
    "    value='The quick brown foxes are running faster than the lazy dogs. They are playing in the garden.',\n",
    "    placeholder='Enter text to process...',\n",
    "    description='Text:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '80%', 'height': '100px'}\n",
    ")\n",
    "\n",
    "method_dropdown = widgets.Dropdown(\n",
    "    options=['All Methods', 'Stemming Only', 'Lemmatization Only'],\n",
    "    value='All Methods',\n",
    "    description='Processing:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '80%'}\n",
    ")\n",
    "\n",
    "def update_advanced_processing(text, method):\n",
    "    \"\"\"Update the advanced processing based on user input\"\"\"\n",
    "    if method == 'All Methods':\n",
    "        advanced_text_processing(text)\n",
    "    elif method == 'Stemming Only':\n",
    "        # Process with stemmers only\n",
    "        words = text.split()\n",
    "        results = {\n",
    "            'Original': words,\n",
    "            'Porter Stemmer': [porter.stem(word) for word in words],\n",
    "            'Lancaster Stemmer': [lancaster.stem(word) for word in words],\n",
    "            'Snowball Stemmer': [snowball.stem(word) for word in words]\n",
    "        }\n",
    "        display(pd.DataFrame(results))\n",
    "    else:\n",
    "        # Process with lemmatizers only\n",
    "        words = text.split()\n",
    "        results = {\n",
    "            'Original': words,\n",
    "            'NLTK Lemmatizer': [lemmatizer.lemmatize(word) for word in words],\n",
    "            'spaCy Lemmatizer': [nlp(word)[0].lemma_ for word in words]\n",
    "        }\n",
    "        display(pd.DataFrame(results))\n",
    "\n",
    "# Create interactive widget\n",
    "interact(update_advanced_processing, text=text_input, method=method_dropdown)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22f021b-ca35-40cc-8d03-4e4822ad8003",
   "metadata": {},
   "source": [
    "### Performance Comparison\n",
    "\n",
    "Let's analyze the performance of different methods on a larger text sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c410c051-f8e8-4d81-a6ac-ecc9f96ece22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1eb04abdb2444c9d7a47a7d6c55a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Textarea(value='The quick brown foxes are running faster than the lazy dogs. They are pl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.analyze_performance(text)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def analyze_performance(text):\n",
    "    \"\"\"Analyze performance of different stemming and lemmatization methods\"\"\"\n",
    "    import time\n",
    "    \n",
    "    # Split text into words\n",
    "    words = text.split()\n",
    "    \n",
    "    # Define methods to test\n",
    "    methods = {\n",
    "        'Porter Stemmer': lambda w: porter.stem(w),\n",
    "        'Lancaster Stemmer': lambda w: lancaster.stem(w),\n",
    "        'Snowball Stemmer': lambda w: snowball.stem(w),\n",
    "        'NLTK Lemmatizer': lambda w: lemmatizer.lemmatize(w),\n",
    "        'spaCy Lemmatizer': lambda w: nlp(w)[0].lemma_\n",
    "    }\n",
    "    \n",
    "    # Measure performance\n",
    "    results = {}\n",
    "    for method_name, method in methods.items():\n",
    "        start_time = time.time()\n",
    "        processed_words = [method(word) for word in words]\n",
    "        end_time = time.time()\n",
    "        \n",
    "        results[method_name] = {\n",
    "            'Time (s)': end_time - start_time,\n",
    "            'Unique Words': len(set(processed_words)),\n",
    "            'Reduction (%)': (len(words) - len(set(processed_words))) / len(words) * 100\n",
    "        }\n",
    "    \n",
    "    # Create performance DataFrame\n",
    "    performance_df = pd.DataFrame(results).T\n",
    "    \n",
    "    # Display results\n",
    "    print(\"Performance Analysis:\")\n",
    "    display(performance_df)\n",
    "    \n",
    "    # Visualize performance\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    performance_df['Time (s)'].plot(kind='bar')\n",
    "    plt.title('Processing Time by Method')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.ylabel('Time (seconds)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Interactive widget for performance analysis\n",
    "performance_input = widgets.Textarea(\n",
    "    value='The quick brown foxes are running faster than the lazy dogs. They are playing in the garden. The weather is nice today.',\n",
    "    placeholder='Enter text for performance analysis...',\n",
    "    description='Text:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '80%', 'height': '100px'}\n",
    ")\n",
    "\n",
    "interact(analyze_performance, text=performance_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32285b65-b225-4838-9d97-58c22fae1787",
   "metadata": {},
   "source": [
    "### Best Practices and Recommendations\n",
    "\n",
    "1. **When to Use Stemming**\n",
    "   - Information retrieval systems\n",
    "   - Search engines\n",
    "   - Document clustering\n",
    "   - When speed is more important than accuracy\n",
    "\n",
    "2. **When to Use Lemmatization**\n",
    "   - Text analysis\n",
    "   - Machine learning models\n",
    "   - Sentiment analysis\n",
    "   - When accuracy is more important than speed\n",
    "\n",
    "3. **Method Selection Guidelines**\n",
    "   - Porter Stemmer: General purpose, balanced approach\n",
    "   - Lancaster Stemmer: More aggressive stemming needed\n",
    "   - Snowball Stemmer: Improved Porter algorithm\n",
    "   - NLTK Lemmatizer: When dictionary-based accuracy is needed\n",
    "   - spaCy Lemmatizer: When working with spaCy pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e1c690-f99c-454c-8083-49e19394ef20",
   "metadata": {},
   "source": [
    "<a id='visualization'></a>\n",
    "## 5. Interactive Visualizations\n",
    "\n",
    "Let's create visual representations of the stemming and lemmatization processes. We'll show how words transform and how different methods affect the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "657f4753-7d9a-4247-a7c7-794e2c06a32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ecd8a0ac9bb45c9999fb58fa5ca62a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Textarea(value='The quick brown foxes are running faster than the lazy dogs.', descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.create_word_transformation_visualization(text)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_word_transformation_visualization(text):\n",
    "    \"\"\"Create interactive visualization of word transformations\"\"\"\n",
    "    # Process text with different methods\n",
    "    words = text.split()\n",
    "    processed_words = {\n",
    "        'Original': words,\n",
    "        'Porter Stemmer': [porter.stem(w) for w in words],\n",
    "        'NLTK Lemmatizer': [lemmatizer.lemmatize(w) for w in words]\n",
    "    }\n",
    "    \n",
    "    # Create transformation network\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes and edges\n",
    "    for i, word in enumerate(words):\n",
    "        G.add_node(f'Original_{i}', word=word, pos=(0, i))\n",
    "        G.add_node(f'Porter_{i}', word=processed_words['Porter Stemmer'][i], pos=(1, i))\n",
    "        G.add_node(f'Lemma_{i}', word=processed_words['NLTK Lemmatizer'][i], pos=(2, i))\n",
    "        \n",
    "        G.add_edge(f'Original_{i}', f'Porter_{i}')\n",
    "        G.add_edge(f'Original_{i}', f'Lemma_{i}')\n",
    "    \n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(15, 8))\n",
    "    pos = nx.get_node_attributes(G, 'pos')\n",
    "    labels = nx.get_node_attributes(G, 'word')\n",
    "    \n",
    "    # Draw the graph\n",
    "    nx.draw(G, pos, labels=labels, with_labels=True, \n",
    "            node_color='lightblue', node_size=2000,\n",
    "            arrowsize=20, font_size=8, font_weight='bold')\n",
    "    \n",
    "    plt.title('Word Transformation Network')\n",
    "    plt.show()\n",
    "    \n",
    "    # Create word frequency visualization\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot original vs processed word frequencies\n",
    "    original_freq = pd.Series(words).value_counts().head(10)\n",
    "    porter_freq = pd.Series(processed_words['Porter Stemmer']).value_counts().head(10)\n",
    "    lemma_freq = pd.Series(processed_words['NLTK Lemmatizer']).value_counts().head(10)\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    original_freq.plot(kind='bar')\n",
    "    plt.title('Original Words')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    porter_freq.plot(kind='bar')\n",
    "    plt.title('Porter Stemmed')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.subplot(1, 3, 3)\n",
    "    lemma_freq.plot(kind='bar')\n",
    "    plt.title('Lemmatized')\n",
    "    plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Interactive widget for visualization\n",
    "viz_text_input = widgets.Textarea(\n",
    "    value='The quick brown foxes are running faster than the lazy dogs.',\n",
    "    placeholder='Enter text for visualization...',\n",
    "    description='Text:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout={'width': '80%', 'height': '100px'}\n",
    ")\n",
    "\n",
    "interact(create_word_transformation_visualization, text=viz_text_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cd7925-05ec-4e6b-8659-808478b87857",
   "metadata": {},
   "source": [
    "<a id='conclusion'></a>\n",
    "## 7. Conclusion and Further Resources\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Stemming vs Lemmatization**\n",
    "   - Stemming is faster but less accurate\n",
    "   - Lemmatization is slower but produces valid words\n",
    "   - Choose based on your specific needs\n",
    "\n",
    "2. **Different Algorithms**\n",
    "   - Porter Stemmer: Balanced approach\n",
    "   - Lancaster Stemmer: More aggressive\n",
    "   - Snowball Stemmer: Improved Porter\n",
    "   - NLTK Lemmatizer: Dictionary-based\n",
    "   - spaCy Lemmatizer: Pipeline integration\n",
    "\n",
    "3. **Best Practices**\n",
    "   - Use stemming for information retrieval\n",
    "   - Use lemmatization for text analysis\n",
    "   - Consider performance vs accuracy trade-offs\n",
    "   - Handle edge cases appropriately\n",
    "\n",
    "### Further Reading\n",
    "\n",
    "- [NLTK Documentation](https://www.nltk.org/)\n",
    "- [spaCy Documentation](https://spacy.io/)\n",
    "- [Natural Language Processing with Python](https://www.nltk.org/book/)\n",
    "- [Stemming and Lemmatization in Python](https://www.datacamp.com/community/tutorials/stemming-lemmatization-python)\n",
    "\n",
    "### Practice Exercises\n",
    "\n",
    "1. **Basic Exercises**\n",
    "   - Try different stemming algorithms on the same word\n",
    "   - Compare stemming vs lemmatization results\n",
    "   - Identify patterns in word transformations\n",
    "\n",
    "2. **Advanced Exercises**\n",
    "   - Build a custom stemmer for specific domains\n",
    "   - Implement hybrid approaches\n",
    "   - Handle domain-specific edge cases\n",
    "\n",
    "3. **Real-World Applications**\n",
    "   - Apply to sentiment analysis\n",
    "   - Use in search engine development\n",
    "   - Implement in chatbot systems\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Explore more advanced NLP concepts:\n",
    "   - Part-of-speech tagging\n",
    "   - Named entity recognition\n",
    "   - Dependency parsing\n",
    "\n",
    "2. Learn about modern approaches:\n",
    "   - BERT-based tokenization\n",
    "   - Contextual embeddings\n",
    "   - Transformer models\n",
    "\n",
    "3. Practice with real-world datasets:\n",
    "   - News articles\n",
    "   - Social media posts\n",
    "   - Customer reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d86a26-6880-410a-b703-85a50e298f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
